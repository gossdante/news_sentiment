{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformer-utils\n",
      "  Downloading transformer_utils-0.1.1-py3-none-any.whl (17 kB)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.33.1-py3-none-any.whl (7.6 MB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ddg12\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformer-utils) (4.66.1)\n",
      "Requirement already satisfied: torch in c:\\users\\ddg12\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformer-utils) (2.0.1)\n",
      "Collecting colorcet\n",
      "  Downloading colorcet-3.0.1-py2.py3-none-any.whl (1.7 MB)\n",
      "     ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "     ---------- ----------------------------- 0.4/1.7 MB 8.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.6/1.7 MB 17.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.7/1.7 MB 13.2 MB/s eta 0:00:00\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "     ---------------------------------------- 0.0/293.3 kB ? eta -:--:--\n",
      "     ------------------------------------- 293.3/293.3 kB 18.9 MB/s eta 0:00:00\n",
      "Collecting pyct>=0.4.4\n",
      "  Downloading pyct-0.5.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in c:\\users\\ddg12\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from seaborn->transformer-utils) (1.25.2)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\ddg12\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from seaborn->transformer-utils) (2.1.0)\n",
      "Collecting matplotlib!=3.6.1,>=3.1\n",
      "  Downloading matplotlib-3.7.2-cp310-cp310-win_amd64.whl (7.5 MB)\n",
      "     ---------------------------------------- 0.0/7.5 MB ? eta -:--:--\n",
      "     ------------ --------------------------- 2.3/7.5 MB 49.0 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 5.1/7.5 MB 65.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  7.5/7.5 MB 59.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  7.5/7.5 MB 59.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  7.5/7.5 MB 59.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 7.5/7.5 MB 30.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ddg12\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torch->transformer-utils) (4.7.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\ddg12\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torch->transformer-utils) (3.12.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ddg12\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torch->transformer-utils) (3.1.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\ddg12\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torch->transformer-utils) (3.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\ddg12\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torch->transformer-utils) (1.12)\n",
      "Requirement already satisfied: colorama in c:\\users\\ddg12\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tqdm->transformer-utils) (0.4.6)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\ddg12\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers->transformer-utils) (0.3.3)\n",
      "Requirement already satisfied: requests in c:\\users\\ddg12\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers->transformer-utils) (2.31.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ddg12\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers->transformer-utils) (2023.8.8)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\ddg12\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers->transformer-utils) (0.13.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in c:\\users\\ddg12\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers->transformer-utils) (0.16.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ddg12\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers->transformer-utils) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ddg12\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers->transformer-utils) (6.0.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ddg12\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers->transformer-utils) (2023.9.0)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-10.0.0-cp310-cp310-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "     ---------------------------------- ----- 2.2/2.5 MB 70.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 MB 80.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.5/2.5 MB 26.9 MB/s eta 0:00:00\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.42.1-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "     ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "     ---------------------------------------  2.1/2.1 MB 67.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.1/2.1 MB 26.9 MB/s eta 0:00:00\n",
      "Collecting pyparsing<3.1,>=2.3.1\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.1.0-cp310-cp310-win_amd64.whl (470 kB)\n",
      "     ---------------------------------------- 0.0/470.4 kB ? eta -:--:--\n",
      "     ------------------------------------- 470.4/470.4 kB 28.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ddg12\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn->transformer-utils) (2.8.2)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.5-cp310-cp310-win_amd64.whl (56 kB)\n",
      "     ---------------------------------------- 0.0/56.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 56.1/56.1 kB 2.9 MB/s eta 0:00:00\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\ddg12\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas>=0.25->seaborn->transformer-utils) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ddg12\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas>=0.25->seaborn->transformer-utils) (2023.3.post1)\n",
      "Collecting param>=1.7.0\n",
      "  Downloading param-1.13.0-py2.py3-none-any.whl (87 kB)\n",
      "     ---------------------------------------- 0.0/87.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 87.3/87.3 kB 5.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ddg12\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jinja2->torch->transformer-utils) (2.1.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ddg12\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->transformers->transformer-utils) (2.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ddg12\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->transformers->transformer-utils) (3.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ddg12\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->transformers->transformer-utils) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ddg12\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->transformers->transformer-utils) (3.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ddg12\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sympy->torch->transformer-utils) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ddg12\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn->transformer-utils) (1.16.0)\n",
      "Installing collected packages: pyparsing, pillow, param, kiwisolver, fonttools, cycler, contourpy, pyct, matplotlib, transformers, seaborn, colorcet, transformer-utils\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\ddg12\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python310\\\\site-packages\\\\transformers\\\\models\\\\deprecated\\\\trajectory_transformer\\\\convert_trajectory_transformer_original_pytorch_checkpoint_to_pytorch.py'\n",
      "HINT: This error might have occurred since this system does not have Windows Long Path support enabled. You can find information on how to enable this at https://pip.pypa.io/warnings/enable-long-paths\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.2.1\n",
      "[notice] To update, run: C:\\Users\\ddg12\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install transformer-utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manage API Key & Use NewsApiClient\n",
    "I've saved my API key in a config file, I've loaded the file and saved my key to a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "\n",
    "APIKEY=config.APIKEY\n",
    "\n",
    "from newsapi import NewsApiClient\n",
    "newsapi = NewsApiClient(api_key=APIKEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are the available sources?\n",
    "I've created a loop to gather all the available sources and save into a dataframe. For clarity sake I've printed the available sources as well as the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many total sources are available?: 128\n",
      "What are the categories?  ['general' 'business' 'technology' 'sports' 'entertainment' 'health'\n",
      " 'science']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sources = newsapi.get_sources()\n",
    "print('How many total sources are available?:',len(sources['sources']))\n",
    "total_sources = len(sources['sources'])\n",
    "sources['sources'][0]\n",
    "\n",
    "id=pd.Series(name='id')\n",
    "name=pd.Series(name='name')\n",
    "description=pd.Series(name='description')\n",
    "url=pd.Series(name='url')\n",
    "category=pd.Series(name='category')\n",
    "language=pd.Series(name='language')\n",
    "country=pd.Series(name='country')\n",
    "#column_names = ['id', 'name', 'description', 'url', 'category', 'language', 'country']\n",
    "\n",
    "for idx,outlet in enumerate(sources['sources']):\n",
    "    id[idx]=outlet['id']\n",
    "    name[idx] = outlet['name']\n",
    "    description[idx] = outlet['description']\n",
    "    url[idx] = outlet['url']\n",
    "    category[idx] = outlet['category']\n",
    "    language[idx] = outlet['language']\n",
    "    country[idx] = outlet['country']\n",
    "sourcedf=pd.concat([id,name,description,url,category,language,country],axis=1)\n",
    "\n",
    "print('What are the categories? ', sourcedf['category'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter the available sources\n",
    "Requirements: English Language, US Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>language</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abc-news</td>\n",
       "      <td>ABC News</td>\n",
       "      <td>Your trusted source for breaking news, analysi...</td>\n",
       "      <td>https://abcnews.go.com</td>\n",
       "      <td>general</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>al-jazeera-english</td>\n",
       "      <td>Al Jazeera English</td>\n",
       "      <td>News, analysis from the Middle East and worldw...</td>\n",
       "      <td>http://www.aljazeera.com</td>\n",
       "      <td>general</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ars-technica</td>\n",
       "      <td>Ars Technica</td>\n",
       "      <td>The PC enthusiast's resource. Power users and ...</td>\n",
       "      <td>http://arstechnica.com</td>\n",
       "      <td>technology</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>associated-press</td>\n",
       "      <td>Associated Press</td>\n",
       "      <td>The AP delivers in-depth coverage on the inter...</td>\n",
       "      <td>https://apnews.com/</td>\n",
       "      <td>general</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>axios</td>\n",
       "      <td>Axios</td>\n",
       "      <td>Axios are a new media company delivering vital...</td>\n",
       "      <td>https://www.axios.com</td>\n",
       "      <td>general</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                name  \\\n",
       "0             abc-news            ABC News   \n",
       "3   al-jazeera-english  Al Jazeera English   \n",
       "6         ars-technica        Ars Technica   \n",
       "8     associated-press    Associated Press   \n",
       "10               axios               Axios   \n",
       "\n",
       "                                          description  \\\n",
       "0   Your trusted source for breaking news, analysi...   \n",
       "3   News, analysis from the Middle East and worldw...   \n",
       "6   The PC enthusiast's resource. Power users and ...   \n",
       "8   The AP delivers in-depth coverage on the inter...   \n",
       "10  Axios are a new media company delivering vital...   \n",
       "\n",
       "                         url    category language country  \n",
       "0     https://abcnews.go.com     general       en      us  \n",
       "3   http://www.aljazeera.com     general       en      us  \n",
       "6     http://arstechnica.com  technology       en      us  \n",
       "8        https://apnews.com/     general       en      us  \n",
       "10     https://www.axios.com     general       en      us  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sourcedf= sourcedf[(sourcedf['language']=='en') & (sourcedf['country']=='us')]\n",
    "sourcedf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are the business sources?\n",
    "First we isolate the business sources based on the category variable.\n",
    "I've displayed the number of business sources as a sanity check, as well as tested that the indexing was working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>language</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>bloomberg</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>Bloomberg delivers business and markets news, ...</td>\n",
       "      <td>http://www.bloomberg.com</td>\n",
       "      <td>business</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>business-insider</td>\n",
       "      <td>Business Insider</td>\n",
       "      <td>Business Insider is a fast-growing business si...</td>\n",
       "      <td>http://www.businessinsider.com</td>\n",
       "      <td>business</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>fortune</td>\n",
       "      <td>Fortune</td>\n",
       "      <td>Fortune 500 Daily and Breaking Business News</td>\n",
       "      <td>http://fortune.com</td>\n",
       "      <td>business</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>117</td>\n",
       "      <td>the-wall-street-journal</td>\n",
       "      <td>The Wall Street Journal</td>\n",
       "      <td>WSJ online coverage of breaking news and curre...</td>\n",
       "      <td>http://www.wsj.com</td>\n",
       "      <td>business</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                       id                     name  \\\n",
       "0     16                bloomberg                Bloomberg   \n",
       "1     18         business-insider         Business Insider   \n",
       "2     36                  fortune                  Fortune   \n",
       "3    117  the-wall-street-journal  The Wall Street Journal   \n",
       "\n",
       "                                         description  \\\n",
       "0  Bloomberg delivers business and markets news, ...   \n",
       "1  Business Insider is a fast-growing business si...   \n",
       "2       Fortune 500 Daily and Breaking Business News   \n",
       "3  WSJ online coverage of breaking news and curre...   \n",
       "\n",
       "                              url  category language country  \n",
       "0        http://www.bloomberg.com  business       en      us  \n",
       "1  http://www.businessinsider.com  business       en      us  \n",
       "2              http://fortune.com  business       en      us  \n",
       "3              http://www.wsj.com  business       en      us  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sources:  4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'bloomberg'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_sources = sourcedf[sourcedf['category']=='business']\n",
    "business_sources = business_sources.reset_index()\n",
    "display(business_sources)\n",
    "print('Number of sources: ',len(business_sources))\n",
    "business_sources['id'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get 30 Days Ago Date in the Proper Format\n",
    "For the loop below to work (on the free tier) we need to only check back 30 days. We will use the datetime package to get todays date and 30 days prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todays Date:  2023-09-10\n",
      "30 Days Ago:  2023-08-11\n"
     ]
    }
   ],
   "source": [
    "# Get 30 Days Ago\n",
    "import datetime\n",
    "from datetime import date, timedelta\n",
    "print('Todays Date: ', date.today().isoformat())\n",
    "print('30 Days Ago: ', (date.today()-timedelta(days=30)).isoformat())\n",
    "startdate=(date.today()-timedelta(days=30)).isoformat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop through all articles \n",
    "There are two layers to this loop, the outer layer loops through the number of business sources (4), while the inner loop gets all the articles from that business source and collects the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business-insider</td>\n",
       "      <td>Lakshmi Varanasi</td>\n",
       "      <td>Apple is reportedly working on the Watch's big...</td>\n",
       "      <td>Apple is planning to release a new model of th...</td>\n",
       "      <td>https://www.businessinsider.com/apple-working-...</td>\n",
       "      <td>2023-08-14T16:03:56Z</td>\n",
       "      <td>Apple has a major redesign of the Apple Watch ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business-insider</td>\n",
       "      <td>htan@insider.com (Huileng Tan)</td>\n",
       "      <td>The billionaire founder of a key Apple supplie...</td>\n",
       "      <td>He said no foreign investor would dare invest ...</td>\n",
       "      <td>https://www.businessinsider.com/foxconn-terry-...</td>\n",
       "      <td>2023-08-28T10:21:20Z</td>\n",
       "      <td>Terry Gou, the billionaire founder of Foxconn ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business-insider</td>\n",
       "      <td>Theron Mohamed</td>\n",
       "      <td>4 Big Tech giants have plowed over $1 trillion...</td>\n",
       "      <td>Apple poured over $600 billion into buybacks i...</td>\n",
       "      <td>https://markets.businessinsider.com/news/stock...</td>\n",
       "      <td>2023-08-30T10:39:42Z</td>\n",
       "      <td>Apple CEO Tim Cook.Richard Drew/AP Images\\r\\n&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business-insider</td>\n",
       "      <td>Pete Syme</td>\n",
       "      <td>Apple, Amazon, and Meta among 6 tech giants de...</td>\n",
       "      <td>The European Union named Alphabet, Amazon, App...</td>\n",
       "      <td>https://www.businessinsider.com/tiktok-and-met...</td>\n",
       "      <td>2023-09-06T11:55:50Z</td>\n",
       "      <td>Google, Apple, Facebook, Amazon, and Microsoft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business-insider</td>\n",
       "      <td>Business Insider</td>\n",
       "      <td>Big Tech salaries revealed: This is what devel...</td>\n",
       "      <td>Big tech salaries unveil earnings of engineers...</td>\n",
       "      <td>https://www.businessinsider.com/big-tech-salar...</td>\n",
       "      <td>2023-08-23T16:47:20Z</td>\n",
       "      <td>Business Insider analyzed salary data for work...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             source                          author  \\\n",
       "0  business-insider                Lakshmi Varanasi   \n",
       "1  business-insider  htan@insider.com (Huileng Tan)   \n",
       "2  business-insider                  Theron Mohamed   \n",
       "3  business-insider                       Pete Syme   \n",
       "4  business-insider                Business Insider   \n",
       "\n",
       "                                               title  \\\n",
       "0  Apple is reportedly working on the Watch's big...   \n",
       "1  The billionaire founder of a key Apple supplie...   \n",
       "2  4 Big Tech giants have plowed over $1 trillion...   \n",
       "3  Apple, Amazon, and Meta among 6 tech giants de...   \n",
       "4  Big Tech salaries revealed: This is what devel...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Apple is planning to release a new model of th...   \n",
       "1  He said no foreign investor would dare invest ...   \n",
       "2  Apple poured over $600 billion into buybacks i...   \n",
       "3  The European Union named Alphabet, Amazon, App...   \n",
       "4  Big tech salaries unveil earnings of engineers...   \n",
       "\n",
       "                                                 url           publishedAt  \\\n",
       "0  https://www.businessinsider.com/apple-working-...  2023-08-14T16:03:56Z   \n",
       "1  https://www.businessinsider.com/foxconn-terry-...  2023-08-28T10:21:20Z   \n",
       "2  https://markets.businessinsider.com/news/stock...  2023-08-30T10:39:42Z   \n",
       "3  https://www.businessinsider.com/tiktok-and-met...  2023-09-06T11:55:50Z   \n",
       "4  https://www.businessinsider.com/big-tech-salar...  2023-08-23T16:47:20Z   \n",
       "\n",
       "                                             content  \n",
       "0  Apple has a major redesign of the Apple Watch ...  \n",
       "1  Terry Gou, the billionaire founder of Foxconn ...  \n",
       "2  Apple CEO Tim Cook.Richard Drew/AP Images\\r\\n<...  \n",
       "3  Google, Apple, Facebook, Amazon, and Microsoft...  \n",
       "4  Business Insider analyzed salary data for work...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init Variables\n",
    "Source=pd.Series(name='source')\n",
    "author=pd.Series(name='author')\n",
    "title=pd.Series(name='title')\n",
    "description=pd.Series(name='description')\n",
    "url=pd.Series(name='url')\n",
    "publishedAt=pd.Series(name='publishedAt')\n",
    "content=pd.Series(name='content')\n",
    "# Use Counter\n",
    "counter=0\n",
    "# Loop through each source \n",
    "for source in business_sources['id']:\n",
    "    news_articles = newsapi.get_everything(q='apple',\n",
    "                                          sources=source,\n",
    "                                          from_param=startdate,\n",
    "                                          )\n",
    "    # Gather data from each article\n",
    "    for idx, article in enumerate(news_articles['articles']):\n",
    "        Source[counter] = article['source']['id']\n",
    "        author[counter] = article['author']\n",
    "        title[counter] = article['title']\n",
    "        description[counter] = article['description']\n",
    "        url[counter] = article['url']\n",
    "        publishedAt[counter] = article['publishedAt']\n",
    "        content[counter] = article['content']\n",
    "        #author=pd.concat([Source,article['author']],axis=1)\n",
    "        #for details in article:\n",
    "        #    print(details['title'])\n",
    "        counter = counter + 1\n",
    "# Combine \n",
    "all_articles = pd.concat([Source, author, title, description, url, publishedAt, content],axis=1)\n",
    "all_articles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "The time has finally come for the namesake of this workbook... Sentiment Analysis.\n",
    "\n",
    "We will attempt a few different methods for sentiment analysis. We'll be using a BERT Transformer model (The \"T\" in BERT), which is a natural language processing model released by google that uses deep learning (convolutional neural networks and recurrent neural networks) to \"understand\" natural language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers.utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ddg12\\OneDrive\\Desktop\\news_sentiment\\sentiment.ipynb Cell 15\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ddg12/OneDrive/Desktop/news_sentiment/sentiment.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ddg12/OneDrive/Desktop/news_sentiment/sentiment.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m BertTokenizer, BertForSequenceClassification\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ddg12/OneDrive/Desktop/news_sentiment/sentiment.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Load BERT Model\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ddg12/OneDrive/Desktop/news_sentiment/sentiment.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m bert_model \u001b[39m=\u001b[39m BertForSequenceClassification\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m'\u001b[39m\u001b[39mbert-base-uncased\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\__init__.py:26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m TYPE_CHECKING\n\u001b[0;32m     25\u001b[0m \u001b[39m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m dependency_versions_check\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[0;32m     29\u001b[0m     _LazyModule,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     46\u001b[0m     logging,\n\u001b[0;32m     47\u001b[0m )\n\u001b[0;32m     50\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mget_logger(\u001b[39m__name__\u001b[39m)  \u001b[39m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\dependency_versions_check.py:16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdependency_versions_table\u001b[39;00m \u001b[39mimport\u001b[39;00m deps\n\u001b[1;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mversions\u001b[39;00m \u001b[39mimport\u001b[39;00m require_version, require_version_core\n\u001b[0;32m     19\u001b[0m \u001b[39m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39m# order specific notes:\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[39m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[0;32m     25\u001b[0m pkgs_to_check_at_runtime \u001b[39m=\u001b[39m [\n\u001b[0;32m     26\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mpython\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtqdm\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mpyyaml\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     38\u001b[0m ]\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'transformers.utils'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "# Load BERT Model\n",
    "bert_model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# preprocess the text\n",
    "text = \"This is a great movie! I really enjoyed it.\"\n",
    "input_ids = torch.tensor([tokenizer.encode(text, add_special_tokens=True)])\n",
    "\n",
    "# classify the text\n",
    "with torch.no_grad():\n",
    "  logits = model(input_ids)\n",
    "\n",
    "# get the predicted label\n",
    "label_idx = logits.argmax().item()\n",
    "\n",
    "# map the label index to a label\n",
    "label_map = {0: \"negative\", 1: \"positive\"}\n",
    "sentiment = label_map[label_idx]\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2023-09-09 23:59:35.684985')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Timestamp.today()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
